import os
import cv2
import math
import csv
import time
import json
import ssl
import queue
import threading
import numpy as np
from datetime import datetime
from picamera2 import Picamera2

import mediapipe as mp
from mediapipe.tasks import python as mp_python
from mediapipe.tasks.python import vision

from paho.mqtt import client as mqtt

# ================== CONFIGURACI√ìN ==================
CAM_SIZE = (640, 480)

FRAMES_INTERVAL      = 30          
FATIGA_PERCLOS       = 40.0
SOMNO_MIN_PERCLOS    = 60.0
MICROSLEEP_FRAMES    = 15

EYE_CLOSED_THRESHOLD = 0.009
YAWN_MAR_THRESHOLD   = 0.65
YAWN_HOLD_FRAMES     = 5

CSV_FILENAME = "session_log.csv"
HEADLESS = os.getenv("HEADLESS", "0") == "1"

# ========== AWS IoT Core ==========
ENDPOINT   = "a1omfl67425kjv-ats.iot.us-east-2.amazonaws.com"
PORT       = 8883
CLIENT_ID  = "rsp5"
TOPIC      = "alertas"

CA_PATH   = "aws/AmazonRootCA1.pem"
CERT_PATH = "aws/certificate.pem.crt"
KEY_PATH  = "aws/private.pem.key"

MODEL_PATH = "facemesh/face_landmarker.task"

frame_queue = queue.Queue(maxsize=1)
annot_queue = queue.Queue(maxsize=1)
stop_event  = threading.Event()

# ================== UMBRALES (conteo por minuto) ==================
BLINK_SOMNO_MAX   = 12
BLINK_FATIGA_MAX  = 20
BLINK_NORM_MIN    = 17
BLINK_NORM_MAX    = 25

YAWN_FATIGA_MIN   = 1
YAWN_FATIGA_MAX   = 4
YAWN_SOMNO_MIN    = 4  

# ================== AUXILIARES DE M√âTRICAS ==================
def euclidean(a, b):
    return math.sqrt((a.x - b.x) ** 2 + (a.y - b.y) ** 2)

def eye_aspect_ratio(landmarks, right=True):
    if right:
        top, bottom = landmarks[145], landmarks[159]
    else:
        top, bottom = landmarks[374], landmarks[386]
    return euclidean(top, bottom)

def mouth_aspect_ratio(landmarks):
    vertical_pairs = [(13, 14), (82, 87), (312, 317)]
    horizontals = (78, 308)
    v_dist = np.mean([euclidean(landmarks[a], landmarks[b]) for a, b in vertical_pairs])
    h_dist = euclidean(landmarks[horizontals[0]], landmarks[horizontals[1]])
    return (v_dist / h_dist) if h_dist > 0 else 0.0

def put_text_rgb(rgb_frame, text, pos=(12, 28), color=(0, 255, 255)):
    cv2.putText(rgb_frame, text, pos, cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 2, cv2.LINE_AA)

def draw_landmarks_on_frame_rgb(rgb_frame, marks):
    h, w = rgb_frame.shape[:2]
    for lm in marks[0]:
        x = int(lm.x * w); y = int(lm.y * h)
        cv2.circle(rgb_frame, (x, y), 1, (0, 255, 0), -1)

# ================== MediaPipe: detector ==================
def initialize_detector():
    if not os.path.exists(MODEL_PATH):
        raise FileNotFoundError(f"Modelo no encontrado: {MODEL_PATH}.")
    base_options = mp_python.BaseOptions(model_asset_path=MODEL_PATH)
    options = vision.FaceLandmarkerOptions(
        base_options=base_options,
        output_face_blendshapes=True,
        output_facial_transformation_matrixes=True,
        num_faces=1
    )
    return vision.FaceLandmarker.create_from_options(options)

# ================== Hilo de Captura ==================
class CaptureWorker(threading.Thread):
    def __init__(self, stop_evt):
        super().__init__(daemon=True)
        self.stop_evt = stop_evt
        self.picam2 = None

    def run(self):
        try:
            self.picam2 = Picamera2()
            cfg = self.picam2.create_preview_configuration(main={"format":"RGB888","size":CAM_SIZE})
            self.picam2.configure(cfg)
            self.picam2.start()
            time.sleep(0.2)
            print("üü¢ C√°mara lista (Picamera2).")
        except Exception as e:
            import traceback
            print(f"‚ùå Error iniciando c√°mara: {e}")
            traceback.print_exc()
            self.stop_evt.set()
            return

        try:
            while not self.stop_evt.is_set():
                try:
                    rgb = self.picam2.capture_array()
                except Exception:
                    time.sleep(0.005)
                    continue

                if frame_queue.full():
                    try: frame_queue.get_nowait()
                    except queue.Empty: pass
                frame_queue.put(rgb)
        except Exception as e:
            import traceback
            print(f"‚ùå Excepci√≥n en CaptureWorker: {e}")
            traceback.print_exc()
            self.stop_evt.set()
        finally:
            try: self.picam2.stop()
            except Exception: pass

# ================== Hilo de Inferencia ==================
class InferenceWorker(threading.Thread):
    def __init__(self, stop_evt):
        super().__init__(daemon=True)
        self.stop_evt = stop_evt

        self.detector = initialize_detector()

        # Estado/m√©tricas
        self.frames_cnt = 0
        self.closed_frames = 0
        self.closed_streak = 0
        self.microsleep_flag = False

        self.blink_count_win = 0
        self.yawn_count_win  = 0
        self.eyes_closed_prev = False
        self.yawn_frames = 0

        self.window_start_ts = time.time()

        # ---- Ventana real de 1 minuto ----
        self.blink_minute_count = 0
        self.blink_minute_start = time.time()

        # CSV
        self.csv_file = open(CSV_FILENAME, mode='w', newline='')
        self.csv_writer = csv.writer(self.csv_file)
        self.csv_writer.writerow(['Timestamp','Estado','PERCLOS (%)','Blinks','Yawns'])

        # MQTT
        self.mqtt_client = mqtt.Client(client_id=CLIENT_ID)
        self.mqtt_client.tls_set(
            ca_certs=CA_PATH,
            certfile=CERT_PATH,
            keyfile=KEY_PATH,
            tls_version=ssl.PROTOCOL_TLSv1_2
        )
        self.mqtt_client.on_connect = self._on_connect
        try:
            self.mqtt_client.connect(ENDPOINT, PORT, keepalive=60)
            self.mqtt_client.loop_start()
            print("üîó MQTT (AWS IoT) inicializado.")
        except Exception as e:
            import traceback
            print(f"‚ö†Ô∏è No se pudo conectar a MQTT: {e}")
            traceback.print_exc()

    def _on_connect(self, client, userdata, flags, rc):
        if rc == 0:
            print("‚úÖ Conectado a AWS IoT Core")
        else:
            print(f"‚ùå Error de conexi√≥n MQTT, c√≥digo: {rc}")

    def _publish(self, payload, qos=1):
        try:
            self.mqtt_client.publish(TOPIC, json.dumps(payload), qos=qos)
        except Exception:
            try: self.mqtt_client.reconnect()
            except Exception:
                pass

    # ---------- Procesamiento ----------
    def _process_metrics(self, marks):
        lms = marks[0]
        ear_r = eye_aspect_ratio(lms, right=True)
        ear_l = eye_aspect_ratio(lms, right=False)
        eyes_closed = (ear_r < EYE_CLOSED_THRESHOLD and ear_l < EYE_CLOSED_THRESHOLD)

        if eyes_closed:
            self.closed_frames += 1
            self.closed_streak += 1
        else:
            self.closed_streak = 0

        if not self.eyes_closed_prev and eyes_closed:
            self.eyes_closed_prev = True
        elif self.eyes_closed_prev and not eyes_closed:
            self.blink_count_win += 1
            self.blink_minute_count += 1   # acumula para ventana de 1 minuto
            self.eyes_closed_prev = False

        mar = mouth_aspect_ratio(lms)
        if mar > YAWN_MAR_THRESHOLD:
            self.yawn_frames += 1
        else:
            if self.yawn_frames > YAWN_HOLD_FRAMES:
                self.yawn_count_win += 1
            self.yawn_frames = 0

        return eyes_closed, mar

    # ---------- Estados ----------
    def _estado_por_blink_minuto(self):
        now = time.time()
        elapsed = now - self.blink_minute_start
        if elapsed < 60.0:
            return None

        blinks = self.blink_minute_count
        print(f"[BLINK_WINDOW] Blinks en 1min = {blinks}")

        if blinks <= BLINK_SOMNO_MAX:
            estado = "SOMNOLENCIA"
        elif blinks <= BLINK_FATIGA_MAX:
            estado = "FATIGA"
        elif BLINK_NORM_MIN <= blinks <= BLINK_NORM_MAX:
            estado = "NORMAL"
        else:
            estado = "NORMAL"

        self.blink_minute_start = now
        self.blink_minute_count = 0
        return estado

    def _estado_por_yawn(self, yawns):
        if yawns > YAWN_SOMNO_MIN:
            return "SOMNOLENCIA"
        if YAWN_FATIGA_MIN <= yawns <= YAWN_FATIGA_MAX:
            return "FATIGA"
        return "NORMAL"

    def _estado_por_perclos(self, perclos):
        if perclos >= SOMNO_MIN_PERCLOS:
            return "SOMNOLENCIA"
        if perclos >= FATIGA_PERCLOS:
            return "FATIGA"
        return "NORMAL"

    def _fusion_decision(self, perclos, yawns):
        if self.microsleep_flag:
            return "MICROSUE√ëO"

        candidatos = []
        cand_blink = self._estado_por_blink_minuto()
        if cand_blink: candidatos.append(cand_blink)
        candidatos.append(self._estado_por_yawn(yawns))
        candidatos.append(self._estado_por_perclos(perclos))

        rank = {"NORMAL":0,"FATIGA":1,"SOMNOLENCIA":2,"MICROSUE√ëO":3}
        return max(candidatos, key=lambda x: rank[x])

    # ---------- Ventana ----------
    def _ventana_cerrar(self):
        perclos = 100.0 * self.closed_frames / float(FRAMES_INTERVAL)
        estado_final = self._fusion_decision(perclos, self.yawn_count_win)
        ts = int(time.time())

        self.csv_writer.writerow([
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            estado_final, round(perclos, 2),
            int(self.blink_count_win), int(self.yawn_count_win)
        ])

        if estado_final != "NORMAL":
            payload = {
                "device_id": CLIENT_ID,
                "estado": estado_final,
                "perclos": round(perclos, 2),
                "blinks": int(self.blink_count_win),
                "yawns": int(self.yawn_count_win),
                "ts": ts
            }
            self._publish(payload)

        print(f"[{datetime.now().strftime('%H:%M:%S')}] Estado={estado_final} | "
              f"PERCLOS={perclos:.2f}% | Blinks={self.blink_count_win} | "
              f"Yawns={self.yawn_count_win} | Microsue√±oFlag={self.microsleep_flag}")

        self.frames_cnt = 0
        self.closed_frames = 0
        self.closed_streak = 0
        self.microsleep_flag = False
        self.blink_count_win = 0
        self.yawn_count_win  = 0
        self.window_start_ts = time.time()

    def run(self):
        try:
            while not self.stop_evt.is_set():
                try: rgb = frame_queue.get(timeout=0.2)
                except queue.Empty: continue

                state_overlay = "NORMAL"
                mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=rgb)
                result = self.detector.detect(mp_image)

                if result.face_landmarks:
                    draw_landmarks_on_frame_rgb(rgb, result.face_landmarks)
                    eyes_closed, mar = self._process_metrics(result.face_landmarks)

                    if eyes_closed: state_overlay = "OJOS CERRADOS"
                    elif mar > YAWN_MAR_THRESHOLD: state_overlay = "BOSTEZO"
                    else: state_overlay = "NORMAL"

                    self.frames_cnt += 1
                    if self.closed_streak >= MICROSLEEP_FRAMES:
                        self.microsleep_flag = True
                        state_overlay = "MICROSUE√ëO"

                    if self.frames_cnt >= FRAMES_INTERVAL:
                        self._ventana_cerrar()
                else:
                    put_text_rgb(rgb, "Sin rostro", (12, 56))

                put_text_rgb(rgb, state_overlay, (12, 28))
                bgr = cv2.cvtColor(rgb, cv2.COLOR_RGB2BGR)
                if annot_queue.full():
                    try: annot_queue.get_nowait()
                    except queue.Empty: pass
                annot_queue.put(bgr)
                frame_queue.task_done()
        finally:
            try: self.csv_file.flush(); self.csv_file.close()
            except: pass
            try: self.mqtt_client.loop_stop(); self.mqtt_client.disconnect()
            except: pass

# ================== MAIN ==================
def main():
    print("Iniciando hilos (captura / inferencia)‚Ä¶")
    cap_t = CaptureWorker(stop_event)
    inf_t = InferenceWorker(stop_event)
    cap_t.start(); inf_t.start()

    print(f"üü¢ Presiona 'q' para salir. HEADLESS={HEADLESS}")
    try:
        while not stop_event.is_set():
            try:
                frame = annot_queue.get(timeout=0.3)
                if not HEADLESS:
                    cv2.imshow("Fatigue Monitor", frame)
                    if (cv2.waitKey(1) & 0xFF) == ord('q'): stop_event.set()
            except queue.Empty: pass
    finally:
        stop_event.set()
        cap_t.join(timeout=2.0)
        inf_t.join(timeout=2.0)
        if not HEADLESS: cv2.destroyAllWindows()
        print("Finalizado.")

if __name__ == "__main__":
    main()
